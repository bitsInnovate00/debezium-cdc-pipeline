# Debezium CDC Pipeline - Project Overview

## ğŸ¯ Project Goal

Create a complete Change Data Capture (CDC) pipeline that:
1. Captures changes from PostgreSQL database
2. Streams events through Apache Kafka
3. Stores data in Apache Ignite 3 in-memory cache
4. All running on Kubernetes

## ğŸ“Š Project Statistics

- **Total Files**: 32
- **Lines of Code/Config**: ~3,300
- **Kubernetes YAML Files**: 14
- **Shell Scripts**: 5
- **Documentation Files**: 6
- **Java Source Files**: 1
- **Docker Images**: 7 (PostgreSQL, Kafka, Zookeeper, Kafka Connect, Ignite, Custom Consumer)

## ğŸ—ï¸ Architecture Diagram

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                         Kubernetes Cluster                               â”‚
â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚
â”‚  â”‚                  Namespace: debezium-pipeline                      â”‚  â”‚
â”‚  â”‚                                                                     â”‚  â”‚
â”‚  â”‚  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                                                 â”‚  â”‚
â”‚  â”‚  â”‚  PostgreSQL  â”‚  Logical Replication (WAL)                      â”‚  â”‚
â”‚  â”‚  â”‚   Database   â”‚â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                            â”‚  â”‚
â”‚  â”‚  â”‚              â”‚                     â”‚                            â”‚  â”‚
â”‚  â”‚  â”‚ Port: 5432   â”‚                     â–¼                            â”‚  â”‚
â”‚  â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜            â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚ Kafka Connect   â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚   + Debezium    â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚                 â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚ Port: 8083      â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  â”‚
â”‚  â”‚        â”‚                               â”‚ Publish CDC Events        â”‚  â”‚
â”‚  â”‚        â”‚                               â–¼                            â”‚  â”‚
â”‚  â”‚        â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚  Apache Kafka   â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚     Broker      â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚                 â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚ Port: 9092      â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  â”‚
â”‚  â”‚        â”‚                               â”‚ Subscribe to Topics       â”‚  â”‚
â”‚  â”‚        â”‚                               â–¼                            â”‚  â”‚
â”‚  â”‚        â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚     Ignite      â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚    Consumer     â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚  (Custom Java)  â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  â”‚
â”‚  â”‚        â”‚                               â”‚ Write via SQL             â”‚  â”‚
â”‚  â”‚        â”‚                               â–¼                            â”‚  â”‚
â”‚  â”‚        â”‚                      â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚ Apache Ignite 3 â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚   Data Grid     â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚   (2 nodes)     â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚                 â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚ Ports: 10800,   â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â”‚        10300    â”‚                  â”‚  â”‚
â”‚  â”‚        â”‚                      â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜                  â”‚  â”‚
â”‚  â”‚        â”‚                                                            â”‚  â”‚
â”‚  â”‚        â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”‚  â”‚
â”‚  â”‚                          Zookeeper (Coordination)                â”‚  â”‚  â”‚
â”‚  â”‚                          Port: 2181                              â”‚  â”‚  â”‚
â”‚  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## ğŸ“ Project Structure

```
debezium/
â”‚
â”œâ”€â”€ ğŸ“˜ Documentation (6 files)
â”‚   â”œâ”€â”€ README.md                    # Main project documentation
â”‚   â”œâ”€â”€ QUICKSTART.md                # Quick start guide
â”‚   â”œâ”€â”€ ARCHITECTURE.md              # Detailed architecture
â”‚   â”œâ”€â”€ CONFIGURATION.md             # Configuration reference
â”‚   â”œâ”€â”€ TROUBLESHOOTING.md           # Troubleshooting guide
â”‚   â””â”€â”€ SUMMARY.md                   # Project summary
â”‚
â”œâ”€â”€ âš™ï¸ Build & Deploy
â”‚   â”œâ”€â”€ Makefile                     # Make commands for easy ops
â”‚   â””â”€â”€ .gitignore                   # Git ignore rules
â”‚
â”œâ”€â”€ ğŸ³ Kubernetes Manifests (14 YAML files)
â”‚   â”œâ”€â”€ namespace.yaml               # Namespace definition
â”‚   â”‚
â”‚   â”œâ”€â”€ postgres/                    # PostgreSQL (3 files)
â”‚   â”‚   â”œâ”€â”€ postgres-configmap.yaml
â”‚   â”‚   â”œâ”€â”€ postgres-deployment.yaml
â”‚   â”‚   â””â”€â”€ postgres-service.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ kafka/                       # Kafka & Zookeeper (4 files)
â”‚   â”‚   â”œâ”€â”€ zookeeper-deployment.yaml
â”‚   â”‚   â”œâ”€â”€ zookeeper-service.yaml
â”‚   â”‚   â”œâ”€â”€ kafka-deployment.yaml
â”‚   â”‚   â””â”€â”€ kafka-service.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ kafka-connect/               # Kafka Connect (2 files)
â”‚   â”‚   â”œâ”€â”€ kafka-connect-deployment.yaml
â”‚   â”‚   â””â”€â”€ kafka-connect-service.yaml
â”‚   â”‚
â”‚   â”œâ”€â”€ ignite/                      # Apache Ignite (3 files)
â”‚   â”‚   â”œâ”€â”€ ignite-config.yaml
â”‚   â”‚   â”œâ”€â”€ ignite-deployment.yaml
â”‚   â”‚   â””â”€â”€ ignite-service.yaml
â”‚   â”‚
â”‚   â””â”€â”€ ignite-consumer/             # Consumer (1 file)
â”‚       â””â”€â”€ ignite-consumer-deployment.yaml
â”‚
â”œâ”€â”€ ğŸ”Œ Connector Configurations (2 JSON files)
â”‚   â”œâ”€â”€ postgres-source-connector.json
â”‚   â””â”€â”€ ignite-sink-connector.json
â”‚
â”œâ”€â”€ â˜• Ignite Consumer Application
â”‚   â”œâ”€â”€ Dockerfile                   # Container image
â”‚   â”œâ”€â”€ pom.xml                      # Maven build
â”‚   â””â”€â”€ src/main/java/com/debezium/ignite/
â”‚       â””â”€â”€ IgniteKafkaConsumer.java # Main application
â”‚
â””â”€â”€ ğŸ”§ Automation Scripts (5 shell scripts)
    â”œâ”€â”€ deploy-all.sh                # Deploy everything
    â”œâ”€â”€ create-connectors.sh         # Create connectors
    â”œâ”€â”€ cleanup.sh                   # Clean up resources
    â”œâ”€â”€ test-pipeline.sh             # Test pipeline
    â””â”€â”€ monitor.sh                   # Monitor system
```

## ğŸš€ Quick Start Commands

### Using Make (Recommended)
```bash
make check-prereqs    # Check prerequisites
make deploy           # Deploy everything
make connectors       # Create connectors
make test             # Test pipeline
make monitor          # Monitor system
make clean            # Cleanup
```

### Using Scripts
```bash
./scripts/deploy-all.sh
./scripts/create-connectors.sh
./scripts/test-pipeline.sh
./scripts/cleanup.sh
```

## ğŸ”„ Data Flow Example

### 1. Insert Operation
```sql
-- In PostgreSQL
INSERT INTO customers (name, email) VALUES ('Alice', 'alice@example.com');
```

### 2. CDC Event Generated
```json
{
  "id": 4,
  "name": "Alice",
  "email": "alice@example.com",
  "created_at": "2025-10-13T12:00:00Z",
  "updated_at": "2025-10-13T12:00:00Z"
}
```

### 3. Published to Kafka
- Topic: `dbserver1.public.customers`
- Key: `{"id": 4}`
- Value: Full record JSON

### 4. Consumed by Ignite Consumer
- Java application reads from Kafka
- Parses JSON message
- Extracts data fields

### 5. Written to Ignite
```sql
MERGE INTO customers (id, name, email) VALUES (4, 'Alice', 'alice@example.com');
```

## ğŸ“¦ Components Version Matrix

| Component | Image/Version | Purpose |
|-----------|---------------|---------|
| PostgreSQL | `postgres:15-alpine` | Source database |
| Zookeeper | `confluentinc/cp-zookeeper:7.5.0` | Kafka coordination |
| Kafka | `confluentinc/cp-kafka:7.5.0` | Message broker |
| Kafka Connect | `debezium/connect:2.4` | CDC runtime |
| Ignite | `apacheignite/ignite3:3.0.0` | In-memory cache |
| Consumer | Custom built (Java 11) | Kafka to Ignite |

## ğŸ“ Key Concepts

### Change Data Capture (CDC)
- Captures database changes in real-time
- Uses PostgreSQL Write-Ahead Log (WAL)
- No application code changes needed
- Minimal performance impact

### Event Streaming
- Decouples source and target systems
- Enables multiple consumers
- Provides durability and replay capability
- Scales horizontally

### In-Memory Caching
- Fast data access
- Distributed storage
- SQL query support
- High availability with replication

### Kubernetes Deployment
- Container orchestration
- Service discovery
- Self-healing
- Horizontal scaling

## ğŸ› ï¸ Available Operations

### Deployment
```bash
make deploy           # Full deployment
make build-consumer   # Build consumer image
make connectors       # Create connectors
```

### Testing
```bash
make test             # Run tests
make insert-test      # Insert test data
make psql             # Connect to PostgreSQL
```

### Monitoring
```bash
make status           # Show status
make monitor          # Live monitoring
make logs             # View all logs
make logs-postgres    # PostgreSQL logs
make logs-kafka       # Kafka logs
make logs-connect     # Kafka Connect logs
make logs-consumer    # Consumer logs
make connector-status # Connector status
make topics           # List Kafka topics
```

### Cleanup
```bash
make clean            # Remove everything
```

## ğŸ“ˆ Production Readiness

### Current: Development Setup
- âœ… Single instance per component
- âœ… No persistence (emptyDir)
- âœ… Simple configuration
- âœ… Easy to deploy and test
- âš ï¸ Not suitable for production

### Recommended: Production Setup
- âœ… 3+ replicas for HA
- âœ… Persistent volumes
- âœ… SSL/TLS encryption
- âœ… Authentication enabled
- âœ… Resource limits configured
- âœ… Monitoring and alerting
- âœ… Backup strategy
- âœ… Disaster recovery plan

See `CONFIGURATION.md` for production setup details.

## ğŸ¯ Use Cases

1. **Real-time Data Replication**
   - Sync data between databases
   - Create read replicas
   - Migrate data

2. **Cache Warming**
   - Populate caches automatically
   - Keep caches in sync
   - Invalidate stale data

3. **Event-Driven Architecture**
   - Trigger downstream processes
   - Audit logging
   - Analytics pipelines

4. **Microservices Data Sharing**
   - Share data between services
   - Maintain eventual consistency
   - Decouple services

## ğŸ” Monitoring Endpoints

| Component | Endpoint | Purpose |
|-----------|----------|---------|
| Kafka Connect | http://localhost:8083 | REST API |
| Ignite REST | http://localhost:10300 | Management API |
| PostgreSQL | localhost:5432 | Database access |
| Kafka | localhost:9092 | Broker |

Use `make forward-*` commands to access locally.

## ğŸ“š Documentation Guide

- **Start Here**: `README.md`
- **Quick Deploy**: `QUICKSTART.md`
- **Understanding**: `ARCHITECTURE.md`
- **Customizing**: `CONFIGURATION.md`
- **Issues**: `TROUBLESHOOTING.md`
- **Overview**: `SUMMARY.md`

## ğŸ¤ Next Steps

1. **Deploy**: `make deploy`
2. **Test**: `make test`
3. **Explore**: `make psql`, insert data, check Kafka
4. **Monitor**: `make monitor`
5. **Learn**: Read documentation files
6. **Customize**: Modify configurations
7. **Scale**: Add more replicas
8. **Secure**: Enable authentication
9. **Monitor**: Add Prometheus/Grafana
10. **Productionize**: Follow production checklist

## âš¡ Performance Tips

- Increase Kafka partitions for parallelism
- Add more Kafka Connect workers
- Scale Ignite cluster for distribution
- Tune JVM heap sizes
- Configure proper batch sizes
- Use connection pooling
- Enable compression

## ğŸ” Security Considerations

- Use Kubernetes Secrets for credentials
- Enable SSL/TLS for all connections
- Configure network policies
- Set up RBAC
- Enable authentication on Kafka
- Use PostgreSQL SSL connections
- Implement audit logging

## ğŸ“ Getting Help

1. Check `TROUBLESHOOTING.md`
2. View component logs: `make logs`
3. Check Kubernetes events
4. Verify configurations
5. Test connectivity between services
6. Review Debezium/Kafka/Ignite docs

## âœ¨ Features Highlights

- âœ… Complete CDC pipeline
- âœ… Kubernetes-native deployment
- âœ… Automated scripts
- âœ… Comprehensive documentation
- âœ… Production-ready architecture
- âœ… Scalable design
- âœ… Easy to customize
- âœ… Well-tested components

## ğŸ Success Criteria

Your deployment is successful when:

1. âœ… All pods are Running (1/1 or 2/2 ready)
2. âœ… Connector status shows RUNNING
3. âœ… Kafka topics are created
4. âœ… Test data flows from PostgreSQL to Ignite
5. âœ… Consumer logs show message processing
6. âœ… No errors in component logs

Run `make test` to verify!
